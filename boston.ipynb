{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import math\n",
    "from functools import reduce\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import tree, linear_model\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.metrics import explained_variance_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to be able to see all columns\n",
    "pd.set_option('display.max_columns', 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime = pd.read_csv(\"./data/crime.csv\", low_memory=False).add_prefix(\"crime_\")\n",
    "police = pd.read_csv(\"./data/police_sta.csv\").add_prefix(\"police_\")\n",
    "fire = pd.read_csv(\"./data/fire_dept.csv\").add_prefix(\"fire_\")\n",
    "community = pd.read_csv(\"./data/community_centers.csv\").add_prefix(\"community_\")\n",
    "parks = pd.read_csv(\"./data/parks.csv\").add_prefix(\"parks_\")\n",
    "\n",
    "crime.name = \"crime\"\n",
    "police.name = \"police\"\n",
    "fire.name = \"fire\"\n",
    "community.name = \"community\"\n",
    "parks.name = \"parks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "humidity = pd.read_csv(\"./data/weather/humidity.csv\")\n",
    "temp = pd.read_csv(\"./data/weather/temperature.csv\")\n",
    "pressure = pd.read_csv(\"./data/weather/pressure.csv\")\n",
    "weather_descript = pd.read_csv(\"./data/weather/weather_description.csv\")\n",
    "wind_dir = pd.read_csv(\"./data/weather/wind_direction.csv\")\n",
    "wind_speed = pd.read_csv(\"./data/weather/wind_speed.csv\")\n",
    "\n",
    "humidity.name = \"humidity\"\n",
    "temp.name = \"temperature\"\n",
    "pressure.name = \"pressure\"\n",
    "weather_descript.name = \"weather_description\"\n",
    "wind_dir.name = \"wind_direction\"\n",
    "wind_speed.name = \"wind_speed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos_weather = []\n",
    "for df in [humidity, temp, pressure, weather_descript, wind_dir, wind_speed]:\n",
    "    df = df.rename({\"Boston\":df.name}, axis=1)\n",
    "    bos_weather.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOTE ###\n",
    "# The following three cells were only to handle the original weather files, which contained many cities\n",
    "# Code kept for posterity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The files have many cities in them\n",
    "#for df in bos_weather:\n",
    "#    df.drop(list(df.filter(regex=\"^((?!Boston|datetime).)*$\")), axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The scraper didn't specify the temp units, which inexplicably default to Kelvin\n",
    "#def temp_k_to_f(kelvin):\n",
    "#    return ((kelvin - 273.15) * 9/5 + 32)\n",
    "#temp['Boston'] = temp['Boston'].apply(temp_k_to_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And, to save upload space, let's write out our new files\n",
    "#for df in bos_weather:\n",
    "#    df.to_csv('./data/weather/' + df.name + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as a SQL inner join\n",
    "weather = reduce(lambda left,right: pd.merge(left,right,on=[\"datetime\"], how=\"inner\"), bos_weather)\n",
    "weather.drop(weather.filter(regex=\"Unnamed\"), axis=1, inplace=True)\n",
    "\n",
    "# First row is NaN due to the join, drop it\n",
    "weather.drop(weather.index[0], inplace=True)\n",
    "datasets = [crime, police, fire, community, parks, weather]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime               False\n",
       "humidity                True\n",
       "temperature             True\n",
       "pressure                True\n",
       "weather_description    False\n",
       "wind_direction         False\n",
       "wind_speed             False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 640,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are still some NaNs, so let's fill them with the closest neighbor\n",
    "weather.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime               False\n",
       "humidity               False\n",
       "temperature            False\n",
       "pressure               False\n",
       "weather_description    False\n",
       "wind_direction         False\n",
       "wind_speed             False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 641,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.fillna(method=\"ffill\", inplace=True)\n",
    "weather.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in datasets:\n",
    "    # Some of the datasets have Lat/Long as Y/X, which can be confusing\n",
    "    # They also have longcoord and latcoord, but they're unsigned, so dropping them\n",
    "    # Regex is to avoid partial matching\n",
    "    df.columns = df.columns.str.replace(\"^[X]\", \"long\", regex=True)\n",
    "    df.columns = df.columns.str.replace(\"^[Y]\", \"lat\", regex=True)\n",
    "    df.drop(list(df.filter(regex=\"coord\")), axis = 1, inplace=True)\n",
    "    \n",
    "    # Makes typing easier\n",
    "    df.columns = [x.lower() for x in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "### crime ###\n",
    "# UCR_PART is Uniform Crime Reporting, and attempts to lump crimes into categories\n",
    "# This is separate from Boston PD's own categorization\n",
    "# Can't do anything without Lat/Long, so we'll have to drop those\n",
    "crime.dropna(subset=[\"crime_lat\", \"crime_long\"], inplace=True)\n",
    "\n",
    "# Renaming for consistency\n",
    "crime = crime.rename({\"crime_occurred_on_date\":\"datetime\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "police_x               False\n",
       "police_y               False\n",
       "police_objectid        False\n",
       "police_bldg_id         False\n",
       "police_bid             False\n",
       "police_address         False\n",
       "police_point_x         False\n",
       "police_point_y         False\n",
       "police_name            False\n",
       "police_neighborhood    False\n",
       "police_city            False\n",
       "police_zip             False\n",
       "police_ft_sqft          True\n",
       "police_story_ht         True\n",
       "police_parcel_id       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 644,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### police ###\n",
    "\n",
    "# None of the nulls here matter\n",
    "police.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fire_x             False\n",
       "fire_y             False\n",
       "fire_objectid_1    False\n",
       "fire_objectid       True\n",
       "fire_bfd_id         True\n",
       "fire_map_id         True\n",
       "fire_mapcode        True\n",
       "fire_loccode        True\n",
       "fire_locdept        True\n",
       "fire_locname        True\n",
       "fire_loccontact     True\n",
       "fire_locphone       True\n",
       "fire_locstno        True\n",
       "fire_locaddr       False\n",
       "fire_locowner       True\n",
       "fire_locward        True\n",
       "fire_locparcl       True\n",
       "fire_locprect       True\n",
       "fire_locplan        True\n",
       "fire_study          True\n",
       "fire_above          True\n",
       "fire_above_desc     True\n",
       "fire_source         True\n",
       "fire_geoaddress    False\n",
       "fire_pd            False\n",
       "fire_ct90           True\n",
       "fire_xcoord         True\n",
       "fire_ycoord         True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### fire ###\n",
    "\n",
    "# Lots of nulls here, but only ones that actually matter are fire_x and fire_y \n",
    "# (fire_xcoord and fire_ycoord are the same, but unsigned)\n",
    "fire.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "community_x           False\n",
       "community_y           False\n",
       "community_fid         False\n",
       "community_objectid     True\n",
       "community_site        False\n",
       "community_phone       False\n",
       "community_fax          True\n",
       "community_street      False\n",
       "community_neigh       False\n",
       "community_zip         False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 646,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### community ###\n",
    "\n",
    "# None of the nulls here matter\n",
    "community.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parks_objectid            False\n",
       "parks_site_name           False\n",
       "parks_ownership           False\n",
       "parks_protection           True\n",
       "parks_typecode            False\n",
       "parks_district            False\n",
       "parks_acres               False\n",
       "parks_address             False\n",
       "parks_zonagg              False\n",
       "parks_typelong            False\n",
       "parks_os_own_jur           True\n",
       "parks_os_mngmnt            True\n",
       "parks_pos                 False\n",
       "parks_pa                  False\n",
       "parks_alt_name             True\n",
       "parks_agncyjuris           True\n",
       "parks_shape_starea__      False\n",
       "parks_shape_stlength__    False\n",
       "parks_shapestarea         False\n",
       "parks_shapestlength       False\n",
       "parks_park_id              True\n",
       "parks_region              False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### parks ###\n",
    "\n",
    "# None of the nulls here matter\n",
    "parks.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime               False\n",
       "humidity               False\n",
       "temperature            False\n",
       "pressure               False\n",
       "weather_description    False\n",
       "wind_direction         False\n",
       "wind_speed             False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### weather ###\n",
    "\n",
    "# No nulls, hooray\n",
    "weather.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to clean up datetime a bit for the next merge\n",
    "\n",
    "# Ensure they're in datetime64 format\n",
    "crime[\"datetime\"] = pd.to_datetime(crime[\"datetime\"].str.replace(\".\", \":\"))\n",
    "weather[\"datetime\"] = pd.to_datetime(weather[\"datetime\"].str.replace(\".\", \":\"))\n",
    "\n",
    "# Sort by date\n",
    "crime.sort_values(by=\"datetime\", inplace=True)\n",
    "weather.sort_values(by=\"datetime\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the crime data is from 2015-2019, and weather from 2012-2017, we'd be throwing out\n",
    "# a lot of data if we only joined on those. As such, we'll examine weather separately\n",
    "# from the other data, which is assumed (big if) to be static\n",
    "\n",
    "# Also to consider is the fact that some of the crime reports almost certainly had the\n",
    "# hour either missing or filled in as 0 by default, so the weather may not always correlate\n",
    "\n",
    "crime_with_weather = pd.merge_asof(crime, weather, \n",
    "                                   on=\"datetime\", \n",
    "                                   direction=\"nearest\",\n",
    "                                   tolerance=pd.Timedelta(\"1 hour\")\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows for which we don't have weather\n",
    "crime_with_weather.dropna(subset=[\"humidity\",\n",
    "                                  \"temperature\",\n",
    "                                  \"pressure\",\n",
    "                                  \"weather_description\",\n",
    "                                  \"wind_direction\",\n",
    "                                  \"wind_speed\"], \n",
    "                          inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sml",
   "language": "python",
   "name": "sml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
